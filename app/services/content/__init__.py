"""
Content Engine - Gera conte√∫do na voz do Caco Fakessen
"""
import os
import re
import random
import logging
from typing import List, Dict, Optional
from pathlib import Path
import requests

from ...persona import PERSONA, get_bordao, get_referencia_primeiro_mundo, get_frase_efeito

logger = logging.getLogger(__name__)


class ContentEngine:
    """
    Gera conte√∫do na voz do Caco Fakessen.
    
    Caracter√≠sticas:
    - Humor √°cido e elitista
    - Compara√ß√µes com primeiro mundo
    - Ironia passivo-agressiva
    - Anti-esquerda/woke/vitimismo
    """
    
    def __init__(self, openai_api_key: str = None, anthropic_api_key: str = None):
        self.openai_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.anthropic_key = anthropic_api_key or os.getenv("ANTHROPIC_API_KEY")
        self.persona = PERSONA
    
    def _get_system_prompt(self) -> str:
        """Retorna o prompt de sistema para a IA"""
        return f"""Voc√™ √© {self.persona['nome']}, conhecido como "{self.persona['apelido']}".

BACKGROUND:
- {self.persona['background']['origem']}
- {self.persona['background']['residencia']}
- {self.persona['background']['educacao']}

PERSONALIDADE:
- Tom: {self.persona['personalidade']['tom']}
- Estilo: {self.persona['personalidade']['estilo']}
- Posicionamento: {self.persona['personalidade']['posicionamento']}
- Vis√£o: {self.persona['personalidade']['visao_pobreza']}

VOC√ä ODEIA: {', '.join(self.persona['personalidade']['odeia'])}
VOC√ä ADMIRA: {', '.join(self.persona['personalidade']['admira'])}

COMO VOC√ä FALA:
{chr(10).join('- ' + c for c in self.persona['voz']['caracteristicas'])}

BORD√ïES QUE USA:
{chr(10).join('- "' + b + '"' for b in self.persona['voz']['bordoes'][:5])}

CIDADES QUE REFERENCIA: {', '.join(self.persona['referencias_primeiro_mundo'][:8])}

REGRAS:
1. Nunca xingue diretamente - use ironia cortante
2. Seja breve e impactante (m√°ximo 280 caracteres)
3. Use compara√ß√µes com primeiro mundo quando relevante
4. Mantenha tom de superioridade refinada, n√£o grosseria
5. Evite hashtags
6. N√£o seja explicitamente pol√≠tico - seja sutil e ir√¥nico
7. O humor √© a arma principal"""
    
    def generate_post(
        self,
        topic: str = None,
        pilar: str = None,
        max_length: int = 280,
        use_ai: bool = True
    ) -> str:
        """
        Gera um post na voz do Caco.
        
        Args:
            topic: Assunto espec√≠fico (opcional)
            pilar: Pilar de conte√∫do (humor_elitista, tech_ia, financas, produtividade, politica_news)
            max_length: Tamanho m√°ximo
            use_ai: Usar IA para gerar
        
        Returns:
            Post no estilo Caco Fakessen
        """
        # Se n√£o especificou pilar, escolhe baseado nas prioridades
        if not pilar:
            pilar = self._choose_pilar()
        
        if use_ai and (self.openai_key or self.anthropic_key):
            return self._generate_with_ai(topic, pilar, max_length)
        else:
            return self._generate_template(pilar)
    
    def _choose_pilar(self) -> str:
        """Escolhe pilar baseado nas prioridades"""
        pilares = self.persona["pilares"]
        # Criar lista ponderada
        choices = []
        for nome, config in pilares.items():
            choices.extend([nome] * config["prioridade"])
        return random.choice(choices)
    
    def _generate_with_ai(self, topic: str, pilar: str, max_length: int) -> str:
        """Gera conte√∫do usando LLM"""
        
        pilar_info = self.persona["pilares"].get(pilar, {})
        exemplos = pilar_info.get("exemplos", [])
        
        prompt = f"""Crie um tweet como Caco Fakessen.

PILAR: {pilar} - {pilar_info.get('descricao', '')}
{'TEMA: ' + topic if topic else 'TEMA: Livre, escolha algo relevante do momento'}

EXEMPLOS DO ESTILO:
{chr(10).join('- ' + e for e in exemplos[:3])}

REGRAS:
- M√°ximo {max_length} caracteres
- Seja ir√¥nico e cortante
- Pode usar compara√ß√£o com primeiro mundo
- Termine com uma "cortada" ou observa√ß√£o √°cida
- N√ÉO use hashtags
- N√ÉO seja expl√≠cito demais - a gra√ßa est√° na sutileza

Retorne APENAS o tweet, sem explica√ß√µes."""

        try:
            if self.anthropic_key:
                return self._call_anthropic(prompt)
            elif self.openai_key:
                return self._call_openai(prompt)
        except Exception as e:
            logger.error(f"Erro na gera√ß√£o com IA: {e}")
        
        return self._generate_template(pilar)
    
    def _call_anthropic(self, prompt: str) -> str:
        """Chama API da Anthropic"""
        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers={
                "x-api-key": self.anthropic_key,
                "content-type": "application/json",
                "anthropic-version": "2023-06-01"
            },
            json={
                "model": "claude-3-haiku-20240307",
                "max_tokens": 300,
                "system": self._get_system_prompt(),
                "messages": [{"role": "user", "content": prompt}]
            },
            timeout=30
        )
        response.raise_for_status()
        return response.json()["content"][0]["text"].strip()
    
    def _call_openai(self, prompt: str) -> str:
        """Chama API da OpenAI"""
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {self.openai_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 300,
                "temperature": 0.9
            },
            timeout=30
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"].strip()
    
    def _generate_template(self, pilar: str) -> str:
        """Gera conte√∫do usando templates"""
        pilar_info = self.persona["pilares"].get(pilar, {})
        exemplos = pilar_info.get("exemplos", [])
        
        if exemplos:
            # Usar exemplo como base e variar
            base = random.choice(exemplos)
            # √Äs vezes adiciona bord√£o
            if random.random() < 0.3:
                base += f" {get_bordao()}"
            return base
        
        # Fallback: frase de efeito + bord√£o
        return f"{get_frase_efeito()} {get_bordao()}"
    
    def generate_reply(
        self,
        original_post: str,
        author: str,
        post_sentiment: str = "neutral",
        use_ai: bool = True
    ) -> str:
        """
        Gera reply na voz do Caco.
        
        Args:
            original_post: Texto do post original
            author: Username do autor
            post_sentiment: Sentimento do post (left, right, neutral, viral_tech, viral_economy)
            use_ai: Usar IA
        """
        # Determinar tipo de reply
        if "esquerda" in post_sentiment or "left" in post_sentiment:
            reply_type = "contra_esquerda"
        elif "direita" in post_sentiment or "right" in post_sentiment:
            reply_type = "concordancia_direita"
        elif "tech" in post_sentiment:
            reply_type = "posts_virais_tech"
        elif "econom" in post_sentiment:
            reply_type = "posts_virais_economia"
        else:
            reply_type = "posts_virais_tech"  # Default
        
        if use_ai and (self.openai_key or self.anthropic_key):
            return self._generate_reply_ai(original_post, author, reply_type)
        else:
            return self._generate_reply_template(reply_type)
    
    def _generate_reply_ai(self, original_post: str, author: str, reply_type: str) -> str:
        """Gera reply usando IA"""
        
        reply_config = self.persona["replies"].get(reply_type, {})
        exemplos = reply_config.get("exemplos", [])
        tom = reply_config.get("tom", "ir√¥nico")
        
        prompt = f"""Crie uma resposta como Caco Fakessen para este tweet de @{author}:

"{original_post}"

TOM ESPERADO: {tom}

EXEMPLOS DO ESTILO:
{chr(10).join('- ' + e for e in exemplos)}

REGRAS:
- M√°ximo 200 caracteres
- Seja ir√¥nico, n√£o grosseiro
- Uma cortada r√°pida e elegante
- N√£o mencione o @ do autor (j√° est√° em reply)
- N√ÉO use hashtags

Retorne APENAS a resposta."""

        try:
            if self.anthropic_key:
                return self._call_anthropic(prompt)
            elif self.openai_key:
                return self._call_openai(prompt)
        except Exception as e:
            logger.error(f"Erro ao gerar reply: {e}")
        
        return self._generate_reply_template(reply_type)
    
    def _generate_reply_template(self, reply_type: str) -> str:
        """Gera reply usando templates"""
        reply_config = self.persona["replies"].get(reply_type, {})
        exemplos = reply_config.get("exemplos", [])
        
        if exemplos:
            return random.choice(exemplos)
        
        return get_bordao()
    
    def generate_thread(
        self,
        topic: str,
        num_tweets: int = 5,
        pilar: str = None
    ) -> List[str]:
        """
        Gera uma thread na voz do Caco.
        """
        if not pilar:
            pilar = self._choose_pilar()
        
        if self.openai_key or self.anthropic_key:
            return self._generate_thread_ai(topic, num_tweets, pilar)
        else:
            return self._generate_thread_template(topic, num_tweets, pilar)
    
    def _generate_thread_ai(self, topic: str, num_tweets: int, pilar: str) -> List[str]:
        """Gera thread usando IA"""
        
        pilar_info = self.persona["pilares"].get(pilar, {})
        
        prompt = f"""Crie uma thread de {num_tweets} tweets como Caco Fakessen sobre: {topic}

PILAR: {pilar} - {pilar_info.get('descricao', '')}

ESTRUTURA:
1/ Hook ir√¥nico que prende aten√ß√£o
2-{num_tweets-1}/ Desenvolvimento com observa√ß√µes √°cidas
{num_tweets}/ Conclus√£o com cortada final

REGRAS:
- Cada tweet m√°ximo 280 caracteres
- Numere os tweets (1/, 2/, etc)
- Mantenha o tom ir√¥nico e elitista
- Pode incluir compara√ß√µes com primeiro mundo
- Termine com observa√ß√£o devastadora
- N√ÉO use hashtags

Formato:
TWEET_1: [conte√∫do]
TWEET_2: [conte√∫do]
..."""

        try:
            if self.anthropic_key:
                response = self._call_anthropic(prompt)
            elif self.openai_key:
                response = self._call_openai(prompt)
            
            tweets = []
            for line in response.split("\n"):
                if line.startswith("TWEET_"):
                    content = line.split(":", 1)[1].strip() if ":" in line else ""
                    if content:
                        tweets.append(content)
            
            return tweets if tweets else self._generate_thread_template(topic, num_tweets, pilar)
            
        except Exception as e:
            logger.error(f"Erro ao gerar thread: {e}")
            return self._generate_thread_template(topic, num_tweets, pilar)
    
    def _generate_thread_template(self, topic: str, num_tweets: int, pilar: str) -> List[str]:
        """Gera thread usando templates"""
        tweets = []
        cidade = get_referencia_primeiro_mundo()
        
        tweets.append(f"1/ Thread sobre {topic}. Ou como eu chamo: 'coisas √≥bvias que o Brasil ainda n√£o entendeu'. üßµ")
        
        pilar_info = self.persona["pilares"].get(pilar, {})
        exemplos = pilar_info.get("exemplos", [])
        
        for i in range(2, num_tweets):
            if exemplos and random.random() < 0.7:
                tweets.append(f"{i}/ {random.choice(exemplos)}")
            else:
                tweets.append(f"{i}/ Em {cidade} isso j√° foi resolvido h√° d√©cadas. Mas aqui ainda estamos discutindo o b√°sico.")
        
        tweets.append(f"{num_tweets}/ Resumindo: {get_frase_efeito()} {get_bordao()}")
        
        return tweets
    
    def generate_reaction_to_news(self, news_headline: str, news_topic: str = "geral") -> str:
        """
        Gera rea√ß√£o a uma not√≠cia no estilo Caco.
        
        √ötil para aproveitar breaking news e aumentar engajamento.
        """
        if self.openai_key or self.anthropic_key:
            prompt = f"""Como Caco Fakessen, reaja a esta not√≠cia:

"{news_headline}"

REGRAS:
- M√°ximo 280 caracteres  
- Seja ir√¥nico, n√£o partid√°rio expl√≠cito
- Pode fazer compara√ß√£o com primeiro mundo
- Use seu humor √°cido caracter√≠stico
- Uma observa√ß√£o cortante sobre a situa√ß√£o
- N√ÉO use hashtags

Retorne APENAS o tweet."""

            try:
                if self.anthropic_key:
                    return self._call_anthropic(prompt)
                elif self.openai_key:
                    return self._call_openai(prompt)
            except Exception as e:
                logger.error(f"Erro ao reagir a not√≠cia: {e}")
        
        # Fallback
        return f"Mais uma not√≠cia do Brasil. {get_bordao()}"
    
    def generate_comparison_post(self) -> str:
        """
        Gera post comparando Brasil com primeiro mundo.
        
        Tipo de conte√∫do que o Caco faz muito bem.
        """
        cidade = get_referencia_primeiro_mundo()
        
        comparacoes = [
            f"Saudades de {cidade}. L√° as pessoas entendem o conceito de fila. Aqui √© luta pela sobreviv√™ncia.",
            f"Em {cidade}, o transporte p√∫blico funciona. Aqui √© roleta russa. Mas a culpa √© sempre do 'sistema', n√©.",
            f"Voltei de {cidade}. L√° n√£o tem funk no √∫ltimo volume √†s 3h da manh√£. Conceito revolucion√°rio.",
            f"Curioso como em {cidade} as cal√ßadas existem. Aqui √© safari urbano.",
            f"Lembrei de {cidade}. L√° voc√™ pode andar com celular na m√£o. Vida de primeiro mundo √© outra coisa.",
            f"Em {cidade}, pontualidade √© b√°sico. Aqui √© virtude rara. Enfim, n√©.",
        ]
        
        return random.choice(comparacoes)
