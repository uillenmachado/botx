"""
Content Engine - Gera conteÃºdo otimizado para o algoritmo do X
"""
import os
import re
import json
import random
import logging
from typing import List, Dict, Optional
from pathlib import Path
import requests

logger = logging.getLogger(__name__)


class ContentEngine:
    """
    Gera conteÃºdo otimizado para maximizar engajamento no X.
    
    Baseado no algoritmo do X:
    - Hooks fortes no inÃ­cio (aumenta dwell time)
    - CTAs para replies (aumenta P(reply))
    - ConteÃºdo emocional (aumenta P(like), P(repost))
    - Perguntas (aumenta P(reply))
    """
    
    # Templates de hooks que funcionam
    HOOKS = [
        "ðŸš¨ Isso vai mudar tudo:",
        "A verdade que ninguÃ©m conta:",
        "VocÃª nÃ£o vai acreditar, mas...",
        "Segredo revelado:",
        "THREAD importante ðŸ§µ",
        "Preciso compartilhar isso:",
        "Descobri algo incrÃ­vel:",
        "AtenÃ§Ã£o, isso Ã© sÃ©rio:",
        "O que ninguÃ©m te fala sobre",
        "Acabei de perceber uma coisa:",
    ]
    
    # CTAs para aumentar replies
    CTAS = [
        "Concorda? ðŸ‘‡",
        "O que vocÃª acha?",
        "Comenta aÃ­ sua opiniÃ£o ðŸ‘‡",
        "Discorda? Me conta por quÃª",
        "RT se vocÃª tambÃ©m pensa assim",
        "Salva esse tweet ðŸ“Œ",
        "Marca quem precisa ver isso",
        "Conta sua experiÃªncia ðŸ‘‡",
        "Qual sua visÃ£o sobre isso?",
        "VocÃª jÃ¡ passou por isso?",
    ]
    
    # Emojis estratÃ©gicos (aumentam CTR)
    EMOJIS = {
        "alert": ["ðŸš¨", "âš ï¸", "ðŸ”¥", "ðŸ’¥", "â—"],
        "positive": ["âœ…", "ðŸ’ª", "ðŸš€", "â­", "ðŸ’¡", "ðŸŽ¯"],
        "thinking": ["ðŸ¤”", "ðŸ’­", "ðŸ§ ", "ðŸ‘€"],
        "money": ["ðŸ’°", "ðŸ’µ", "ðŸ“ˆ", "ðŸ’Ž"],
        "tech": ["ðŸ¤–", "ðŸ’»", "ðŸ“±", "âš¡"],
    }
    
    def __init__(self, openai_api_key: str = None, anthropic_api_key: str = None):
        self.openai_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        self.anthropic_key = anthropic_api_key or os.getenv("ANTHROPIC_API_KEY")
        self.content_dir = Path(__file__).parent.parent.parent / "content"
        self.content_dir.mkdir(exist_ok=True)
    
    def generate_post(
        self,
        topic: str,
        style: str = "informativo",
        include_hook: bool = True,
        include_cta: bool = True,
        max_length: int = 280,
        use_ai: bool = True
    ) -> str:
        """
        Gera um post otimizado para o algoritmo.
        
        Args:
            topic: Assunto do post
            style: Estilo (informativo, provocativo, humor, inspiracional)
            include_hook: Incluir hook no inÃ­cio
            include_cta: Incluir CTA no final
            max_length: Tamanho mÃ¡ximo (280 para tweet normal)
            use_ai: Usar IA para gerar conteÃºdo
        
        Returns:
            Post formatado e otimizado
        """
        if use_ai and (self.openai_key or self.anthropic_key):
            return self._generate_with_ai(topic, style, include_hook, include_cta, max_length)
        else:
            return self._generate_template(topic, style, include_hook, include_cta, max_length)
    
    def _generate_with_ai(
        self,
        topic: str,
        style: str,
        include_hook: bool,
        include_cta: bool,
        max_length: int
    ) -> str:
        """Gera conteÃºdo usando LLM"""
        
        prompt = f"""Crie um tweet viral sobre: {topic}

Estilo: {style}
{'Comece com um hook forte que prenda atenÃ§Ã£o.' if include_hook else ''}
{'Termine com um CTA que incentive comentÃ¡rios.' if include_cta else ''}

Regras:
- MÃ¡ximo {max_length} caracteres
- Use 1-2 emojis estrategicamente
- Seja direto e impactante
- Evite hashtags (algoritmo do X nÃ£o prioriza mais)
- Foque em gerar engajamento (replies, likes, reposts)

Retorne APENAS o tweet, sem explicaÃ§Ãµes."""

        try:
            if self.anthropic_key:
                return self._call_anthropic(prompt)
            elif self.openai_key:
                return self._call_openai(prompt)
        except Exception as e:
            logger.error(f"Erro na geraÃ§Ã£o com IA: {e}")
        
        return self._generate_template(topic, style, include_hook, include_cta, max_length)
    
    def _call_anthropic(self, prompt: str) -> str:
        """Chama API da Anthropic"""
        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers={
                "x-api-key": self.anthropic_key,
                "content-type": "application/json",
                "anthropic-version": "2023-06-01"
            },
            json={
                "model": "claude-3-haiku-20240307",
                "max_tokens": 300,
                "messages": [{"role": "user", "content": prompt}]
            },
            timeout=30
        )
        response.raise_for_status()
        return response.json()["content"][0]["text"].strip()
    
    def _call_openai(self, prompt: str) -> str:
        """Chama API da OpenAI"""
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {self.openai_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": "gpt-3.5-turbo",
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 300,
                "temperature": 0.8
            },
            timeout=30
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"].strip()
    
    def _generate_template(
        self,
        topic: str,
        style: str,
        include_hook: bool,
        include_cta: bool,
        max_length: int
    ) -> str:
        """Gera conteÃºdo usando templates"""
        parts = []
        
        if include_hook:
            parts.append(random.choice(self.HOOKS))
        
        # Corpo baseado no estilo
        body = self._get_body_template(topic, style)
        parts.append(body)
        
        if include_cta:
            parts.append(random.choice(self.CTAS))
        
        result = "\n\n".join(parts)
        
        # Truncar se necessÃ¡rio
        if len(result) > max_length:
            result = result[:max_length-3] + "..."
        
        return result
    
    def _get_body_template(self, topic: str, style: str) -> str:
        """Retorna template de corpo baseado no estilo"""
        templates = {
            "informativo": [
                f"Sobre {topic}:\n\nA maioria das pessoas nÃ£o sabe disso, mas Ã© fundamental entender.",
                f"{topic} - o que vocÃª precisa saber:\n\n1. Ã‰ mais simples do que parece\n2. Os resultados vÃªm com consistÃªncia",
            ],
            "provocativo": [
                f"Vou ser direto: {topic} Ã© uma mentira que te contaram.\n\nA realidade Ã© bem diferente.",
                f"Chega de {topic}.\n\nTÃ¡ na hora de encarar a verdade.",
            ],
            "humor": [
                f"Eu tentando entender {topic}:\n\nðŸ¤¡ <- eu\n\nMas pelo menos Ã© divertido.",
                f"{topic} be like:\n\n- Promete muito\n- Entrega pouco\n- Todo mundo finge que funciona",
            ],
            "inspiracional": [
                f"{topic} mudou minha vida.\n\nNÃ£o foi fÃ¡cil, mas valeu cada segundo de dedicaÃ§Ã£o.",
                f"Se eu consegui com {topic}, vocÃª tambÃ©m consegue.\n\nÃ‰ sÃ³ comeÃ§ar.",
            ]
        }
        
        style_templates = templates.get(style, templates["informativo"])
        return random.choice(style_templates)
    
    def generate_reply(
        self,
        original_post: str,
        author: str,
        tone: str = "agreeable",
        add_value: bool = True
    ) -> str:
        """
        Gera uma resposta inteligente para um post.
        
        EstratÃ©gia do algoritmo:
        - Replies que adicionam valor tÃªm mais visibilidade
        - Concordar parcialmente gera mais discussÃ£o
        - Perguntas aumentam P(reply) do autor original
        
        Args:
            original_post: Texto do post original
            author: Username do autor
            tone: Tom da resposta (agreeable, contrarian, curious, supportive)
            add_value: Se deve adicionar informaÃ§Ã£o extra
        """
        if self.openai_key or self.anthropic_key:
            return self._generate_reply_ai(original_post, author, tone, add_value)
        else:
            return self._generate_reply_template(original_post, author, tone)
    
    def _generate_reply_ai(
        self,
        original_post: str,
        author: str,
        tone: str,
        add_value: bool
    ) -> str:
        """Gera reply usando IA"""
        
        tone_instructions = {
            "agreeable": "Concorde e adicione uma perspectiva complementar",
            "contrarian": "Discorde educadamente com um ponto de vista diferente",
            "curious": "FaÃ§a uma pergunta inteligente sobre o tema",
            "supportive": "Apoie a ideia e compartilhe uma experiÃªncia relacionada"
        }
        
        prompt = f"""Crie uma resposta para este tweet de @{author}:

"{original_post}"

InstruÃ§Ãµes:
- Tom: {tone_instructions.get(tone, tone_instructions['agreeable'])}
- {'Adicione um fato ou insight extra que enriqueÃ§a a discussÃ£o' if add_value else 'Seja breve e direto'}
- MÃ¡ximo 200 caracteres
- NÃ£o use hashtags
- Seja genuÃ­no, evite parecer bot
- Pode mencionar @{author} se fizer sentido

Retorne APENAS a resposta, sem explicaÃ§Ãµes."""

        try:
            if self.anthropic_key:
                return self._call_anthropic(prompt)
            elif self.openai_key:
                return self._call_openai(prompt)
        except Exception as e:
            logger.error(f"Erro ao gerar reply com IA: {e}")
        
        return self._generate_reply_template(original_post, author, tone)
    
    def _generate_reply_template(
        self,
        original_post: str,
        author: str,
        tone: str
    ) -> str:
        """Gera reply usando templates"""
        
        templates = {
            "agreeable": [
                "Exatamente isso! ðŸ‘",
                "Concordo 100%. Mais pessoas precisam entender isso.",
                f"@{author} falou tudo. Sem mais.",
                "Isso resume perfeitamente. ðŸŽ¯",
            ],
            "contrarian": [
                "Interessante perspectiva, mas discordo em um ponto...",
                "Entendo o raciocÃ­nio, mas jÃ¡ pensou por outro Ã¢ngulo?",
                "Respeito a visÃ£o, mas minha experiÃªncia foi diferente.",
            ],
            "curious": [
                "Interessante! VocÃª poderia elaborar mais sobre isso?",
                "Faz sentido. Mas como isso funciona na prÃ¡tica?",
                "Boa reflexÃ£o. O que te levou a essa conclusÃ£o?",
            ],
            "supportive": [
                "Passei por algo parecido. Fico feliz que mais gente fale disso! ðŸ’ª",
                "Precisamos de mais conteÃºdo assim. Valeu por compartilhar!",
                f"@{author} sempre trazendo conteÃºdo de qualidade. ðŸ”¥",
            ]
        }
        
        return random.choice(templates.get(tone, templates["agreeable"]))
    
    def generate_thread(
        self,
        topic: str,
        num_tweets: int = 5,
        style: str = "informativo"
    ) -> List[str]:
        """
        Gera uma thread completa.
        
        Threads tÃªm alto P(dwell) e P(repost) quando bem feitas.
        """
        if self.openai_key or self.anthropic_key:
            return self._generate_thread_ai(topic, num_tweets, style)
        else:
            return self._generate_thread_template(topic, num_tweets)
    
    def _generate_thread_ai(
        self,
        topic: str,
        num_tweets: int,
        style: str
    ) -> List[str]:
        """Gera thread usando IA"""
        
        prompt = f"""Crie uma thread de {num_tweets} tweets sobre: {topic}

Estilo: {style}

Estrutura:
1. Tweet 1: Hook forte + promessa do que vem
2. Tweets 2-{num_tweets-1}: ConteÃºdo principal, um ponto por tweet
3. Tweet {num_tweets}: Resumo + CTA forte

Regras:
- Cada tweet mÃ¡ximo 280 caracteres
- Numere os tweets (1/, 2/, etc)
- Use emojis estrategicamente
- Termine com CTA para retweet/follow
- Cada tweet deve fazer sentido sozinho mas conectar com o prÃ³ximo

Formato de resposta:
TWEET_1: [conteÃºdo]
TWEET_2: [conteÃºdo]
...etc"""

        try:
            if self.anthropic_key:
                response = self._call_anthropic(prompt)
            elif self.openai_key:
                response = self._call_openai(prompt)
            
            # Parse response
            tweets = []
            for line in response.split("\n"):
                if line.startswith("TWEET_"):
                    content = line.split(":", 1)[1].strip() if ":" in line else ""
                    if content:
                        tweets.append(content)
            
            return tweets if tweets else self._generate_thread_template(topic, num_tweets)
            
        except Exception as e:
            logger.error(f"Erro ao gerar thread com IA: {e}")
            return self._generate_thread_template(topic, num_tweets)
    
    def _generate_thread_template(self, topic: str, num_tweets: int) -> List[str]:
        """Gera thread usando templates"""
        tweets = [
            f"ðŸ§µ THREAD: Tudo sobre {topic}\n\nVou explicar de forma simples. Bora? ðŸ‘‡",
        ]
        
        for i in range(2, num_tweets):
            tweets.append(f"{i}/ Ponto importante sobre {topic}:\n\n[Desenvolver conteÃºdo aqui]")
        
        tweets.append(
            f"{num_tweets}/ Resumindo:\n\n{topic} Ã© mais simples do que parece.\n\n"
            "Gostou? RT para ajudar mais pessoas! ðŸ”„\n\n"
            "Me segue para mais conteÃºdo assim ðŸ‘Š"
        )
        
        return tweets
    
    def optimize_for_algorithm(self, text: str) -> str:
        """
        Otimiza um texto para o algoritmo do X.
        
        Ajustes baseados no que o algoritmo prioriza:
        - Remove hashtags excessivas (nÃ£o ajudam mais)
        - Adiciona line breaks (aumenta dwell time)
        - Verifica comprimento ideal
        """
        # Remover hashtags (algoritmo do X nÃ£o prioriza mais)
        text = re.sub(r'#\w+', '', text)
        
        # Limpar espaÃ§os mÃºltiplos
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Adicionar quebras de linha para legibilidade
        if len(text) > 100 and '\n' not in text:
            # Quebrar em frases
            sentences = text.replace('. ', '.\n\n')
            text = sentences
        
        return text.strip()
